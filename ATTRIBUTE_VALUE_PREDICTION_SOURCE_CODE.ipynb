{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9286694,"sourceType":"datasetVersion","datasetId":5621625},{"sourceId":82982,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":69710,"modelId":94840}],"dockerImageVersionId":30761,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-04T18:26:46.937387Z","iopub.execute_input":"2024-09-04T18:26:46.937853Z","iopub.status.idle":"2024-09-04T18:26:47.420376Z","shell.execute_reply.started":"2024-09-04T18:26:46.937807Z","shell.execute_reply":"2024-09-04T18:26:47.419228Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/t5-small/tensorflow2/default/1/config.json\n/kaggle/input/t5-small/tensorflow2/default/1/spiece.model\n/kaggle/input/t5-small/tensorflow2/default/1/training_args.bin\n/kaggle/input/t5-small/tensorflow2/default/1/tokenizer_config.json\n/kaggle/input/t5-small/tensorflow2/default/1/model.safetensors\n/kaggle/input/t5-small/tensorflow2/default/1/special_tokens_map.json\n/kaggle/input/t5-small/tensorflow2/default/1/added_tokens.json\n/kaggle/input/t5-small/tensorflow2/default/1/generation_config.json\n/kaggle/input/attribute-value-prediction/attribute_train.data\n/kaggle/input/attribute-value-prediction/attribute_val.solution\n/kaggle/input/attribute-value-prediction/attribute_val.data\n/kaggle/input/attribute-value-prediction/attribute_train.solution\n/kaggle/input/attribute-value-prediction/attribute_test.data\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install datasets","metadata":{"execution":{"iopub.status.busy":"2024-09-04T18:26:47.422491Z","iopub.execute_input":"2024-09-04T18:26:47.423039Z","iopub.status.idle":"2024-09-04T18:27:24.621813Z","shell.execute_reply.started":"2024-09-04T18:26:47.422995Z","shell.execute_reply":"2024-09-04T18:27:24.620238Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.21.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (17.0.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.24.6)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.7.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments, TrainerCallback\nfrom datasets import Dataset, DatasetDict\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-09-04T18:27:24.623674Z","iopub.execute_input":"2024-09-04T18:27:24.624084Z","iopub.status.idle":"2024-09-04T18:27:47.531056Z","shell.execute_reply.started":"2024-09-04T18:27:24.624042Z","shell.execute_reply":"2024-09-04T18:27:47.529764Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def read_jsonl(file_path, nrows=None):\n    df = pd.read_json(file_path, lines=True, nrows=nrows)\n    if 'parent_asin' in df.columns:  # Ensure that the 'parent_asin' column is not used\n        df = df.drop(columns=['parent_asin'])\n    return df\n\n# Load Training Data\ntrain_data = read_jsonl('/kaggle/input/attribute-value-prediction/attribute_train.data',nrows=5000 )\ntrain_solution = read_jsonl('/kaggle/input/attribute-value-prediction/attribute_train.solution',nrows=5000)\n\n# Load Testing Data (No solution file is provided, so we comment it out)\ntest_data = read_jsonl('/kaggle/input/attribute-value-prediction/attribute_test.data',)\n# test_solution = read_jsonl('./data/attrebute_test.solution', nrows=200)  # Comment this line out\n\n# Load Validation Data\nval_data = read_jsonl('/kaggle/input/attribute-value-prediction/attribute_val.data',nrows=1000)\nval_solution = read_jsonl('/kaggle/input/attribute-value-prediction/attribute_val.solution',nrows=1000)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T18:27:47.533651Z","iopub.execute_input":"2024-09-04T18:27:47.534428Z","iopub.status.idle":"2024-09-04T18:27:48.415333Z","shell.execute_reply.started":"2024-09-04T18:27:47.534384Z","shell.execute_reply":"2024-09-04T18:27:48.413952Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom datasets import Dataset\n\n# Function to preprocess the data\ndef preprocess_data(data, solution):\n    # Merge the data with the corresponding solution on 'indoml_id'\n    merged = pd.merge(data, solution, on='indoml_id')\n\n    # Create input_text by combining title, store, and manufacturer details\n    merged['input_text'] = merged.apply(lambda row: f\"title: {row['title']} store: {row['store']} details_Manufacturer: {row['details_Manufacturer']}\", axis=1)\n\n    # Create target_text by combining brand and category details\n    merged['target_text'] = merged.apply(lambda row: f\"details_Brand: {row['details_Brand']} L0_category: {row['L0_category']} L1_category: {row['L1_category']} L2_category: {row['L2_category']} L3_category: {row['L3_category']} L4_category: {row['L4_category']}\", axis=1)\n\n    # Return the processed data with input_text and target_text columns\n    return merged[['input_text', 'target_text']]\n\n# Apply preprocessing to training and validation data\ntrain_processed = preprocess_data(train_data, train_solution)\nval_processed = preprocess_data(val_data, val_solution)\n\n# Since there's no test_solution, we do not process the test data for now\n# test_processed = preprocess_data(test_data, test_solution)\n\n# Convert the processed pandas DataFrames into Hugging Face Dataset format\ntrain_dataset = Dataset.from_pandas(train_processed)\nval_dataset = Dataset.from_pandas(val_processed)\n\n# Note: Test dataset is not processed as there's no test solution\n# test_dataset = Dataset.from_pandas(test_processed)  # Commented out since no test_solution","metadata":{"execution":{"iopub.status.busy":"2024-09-04T18:27:48.416965Z","iopub.execute_input":"2024-09-04T18:27:48.417489Z","iopub.status.idle":"2024-09-04T18:27:48.879292Z","shell.execute_reply.started":"2024-09-04T18:27:48.417433Z","shell.execute_reply":"2024-09-04T18:27:48.877890Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def preprocess_data_no_solution(data):\n    # Prepare input_text for test dataset, without target_text\n    data['input_text'] = data.apply(lambda row: f\"title: {row['title']} store: {row['store']} details_Manufacturer: {row['details_Manufacturer']}\", axis=1)\n    return data[['input_text']]\n\n# Preprocess the test data\ntest_processed = preprocess_data_no_solution(test_data)\n\n# Convert to Hugging Face Dataset format\ntest_dataset = Dataset.from_pandas(test_processed)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T18:27:48.881167Z","iopub.execute_input":"2024-09-04T18:27:48.881927Z","iopub.status.idle":"2024-09-04T18:27:51.281184Z","shell.execute_reply.started":"2024-09-04T18:27:48.881878Z","shell.execute_reply":"2024-09-04T18:27:51.279920Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"dataset_dict = DatasetDict({\n    'train': train_dataset,\n    #'test': test_dataset,\n    'validation': val_dataset\n})","metadata":{"execution":{"iopub.status.busy":"2024-09-04T18:27:51.282677Z","iopub.execute_input":"2024-09-04T18:27:51.283102Z","iopub.status.idle":"2024-09-04T18:27:51.288492Z","shell.execute_reply.started":"2024-09-04T18:27:51.283058Z","shell.execute_reply":"2024-09-04T18:27:51.287311Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"tokenizer = T5Tokenizer.from_pretrained('/kaggle/input/t5-small/tensorflow2/default/1')\nmodel = T5ForConditionalGeneration.from_pretrained('/kaggle/input/t5-small/tensorflow2/default/1')","metadata":{"execution":{"iopub.status.busy":"2024-09-04T18:27:51.290554Z","iopub.execute_input":"2024-09-04T18:27:51.291072Z","iopub.status.idle":"2024-09-04T18:27:52.610887Z","shell.execute_reply.started":"2024-09-04T18:27:51.291015Z","shell.execute_reply":"2024-09-04T18:27:52.609825Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def preprocess_function(examples):\n    inputs = examples['input_text']\n    targets = examples['target_text']\n\n    # Tokenize input texts\n    model_inputs = tokenizer(inputs, max_length=352, padding='max_length', truncation=True)\n\n    # Tokenize target texts (labels)\n    labels = tokenizer(targets, max_length=128, padding='max_length', truncation=True)\n\n    # Add labels to model inputs\n    model_inputs['labels'] = labels['input_ids']\n\n    return model_inputs\n\n# Apply preprocessing to the training and validation datasets\ntokenized_datasets = dataset_dict.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T18:27:52.612530Z","iopub.execute_input":"2024-09-04T18:27:52.613015Z","iopub.status.idle":"2024-09-04T18:27:57.989520Z","shell.execute_reply.started":"2024-09-04T18:27:52.612898Z","shell.execute_reply":"2024-09-04T18:27:57.988219Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08de67c75a3745b28c924aaf774c7367"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a63169043cb456fbd8917722b767152"}},"metadata":{}}]},{"cell_type":"code","source":"def preprocess_test_function(examples):\n    inputs = examples['input_text']\n    # Tokenize input texts\n    model_inputs = tokenizer(inputs, max_length=352, padding='max_length', truncation=True)\n    # Provide default labels or placeholders for test data\n    model_inputs['labels'] = [-100] * len(model_inputs['input_ids'])\n    return model_inputs\n\n# Apply preprocessing to the test dataset\ntokenized_test_dataset = test_dataset.map(preprocess_test_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T18:27:57.994229Z","iopub.execute_input":"2024-09-04T18:27:57.994627Z","iopub.status.idle":"2024-09-04T18:28:43.173718Z","shell.execute_reply.started":"2024-09-04T18:27:57.994587Z","shell.execute_reply":"2024-09-04T18:28:43.172447Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/95036 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e74f68bcbac499a9144fb836ccc092e"}},"metadata":{}}]},{"cell_type":"code","source":"combined_dataset_dict = DatasetDict({\n    'train': tokenized_datasets['train'],\n    'test': tokenized_test_dataset,\n    'validation': tokenized_datasets['validation']\n})","metadata":{"execution":{"iopub.status.busy":"2024-09-04T18:28:43.175205Z","iopub.execute_input":"2024-09-04T18:28:43.175611Z","iopub.status.idle":"2024-09-04T18:28:43.182047Z","shell.execute_reply.started":"2024-09-04T18:28:43.175568Z","shell.execute_reply":"2024-09-04T18:28:43.180797Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir='./results',\n    eval_strategy='epoch',\n    learning_rate=2e-3,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=2,\n    weight_decay=0.01,\n    save_total_limit=3,\n    logging_dir='./logs',\n    logging_steps=800,\n    report_to='none'\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T18:28:43.183946Z","iopub.execute_input":"2024-09-04T18:28:43.184461Z","iopub.status.idle":"2024-09-04T18:28:43.200543Z","shell.execute_reply.started":"2024-09-04T18:28:43.184402Z","shell.execute_reply":"2024-09-04T18:28:43.199246Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class CustomCallback(TrainerCallback):\n    def on_log(self, args, state, control, logs=None, **kwargs):\n        if logs is not None:\n            print(f\"Step: {state.global_step}\")\n            for key, value in logs.items():\n                print(f\"{key}: {value}\")\n            print(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-09-04T18:28:43.202241Z","iopub.execute_input":"2024-09-04T18:28:43.203079Z","iopub.status.idle":"2024-09-04T18:28:43.215443Z","shell.execute_reply.started":"2024-09-04T18:28:43.203018Z","shell.execute_reply":"2024-09-04T18:28:43.214246Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_datasets['train'],\n    eval_dataset=tokenized_datasets['validation'],\n    callbacks=[CustomCallback()]\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-09-04T18:28:43.216944Z","iopub.execute_input":"2024-09-04T18:28:43.217347Z","iopub.status.idle":"2024-09-04T21:26:14.293746Z","shell.execute_reply.started":"2024-09-04T18:28:43.217290Z","shell.execute_reply":"2024-09-04T21:26:14.290516Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1250/1250 2:57:17, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.098507</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.188900</td>\n      <td>0.071038</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"Step: 625\neval_loss: 0.09850655496120453\neval_runtime: 263.7436\neval_samples_per_second: 3.792\neval_steps_per_second: 0.474\nepoch: 1.0\n\n\nStep: 800\nloss: 0.1889\ngrad_norm: 0.34773051738739014\nlearning_rate: 0.0007199999999999999\nepoch: 1.28\n\n\nStep: 1250\neval_loss: 0.07103800028562546\neval_runtime: 265.5944\neval_samples_per_second: 3.765\neval_steps_per_second: 0.471\nepoch: 2.0\n\n\nStep: 1250\ntrain_runtime: 10649.3306\ntrain_samples_per_second: 0.939\ntrain_steps_per_second: 0.117\ntotal_flos: 930474885120000.0\ntrain_loss: 0.14970188903808593\nepoch: 2.0\n\n\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1250, training_loss=0.14970188903808593, metrics={'train_runtime': 10649.3306, 'train_samples_per_second': 0.939, 'train_steps_per_second': 0.117, 'total_flos': 930474885120000.0, 'train_loss': 0.14970188903808593, 'epoch': 2.0})"},"metadata":{}}]},{"cell_type":"code","source":"model.save_pretrained('./fine_tuned_t5_1000dp')\ntokenizer.save_pretrained('./fine_tuned_t5_1000dp')","metadata":{"execution":{"iopub.status.busy":"2024-09-04T21:26:14.298659Z","iopub.execute_input":"2024-09-04T21:26:14.299256Z","iopub.status.idle":"2024-09-04T21:26:14.913577Z","shell.execute_reply.started":"2024-09-04T21:26:14.299200Z","shell.execute_reply":"2024-09-04T21:26:14.912221Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"('./fine_tuned_t5_1000dp/tokenizer_config.json',\n './fine_tuned_t5_1000dp/special_tokens_map.json',\n './fine_tuned_t5_1000dp/spiece.model',\n './fine_tuned_t5_1000dp/added_tokens.json')"},"metadata":{}}]},{"cell_type":"code","source":"import re\nfrom transformers import T5ForConditionalGeneration, T5Tokenizer\nimport torch\nfrom tqdm import tqdm\n\n# Set device to GPU (cuda) if available, otherwise CPU\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n# Load the fine-tuned model and tokenizer from the directory\nmodel = T5ForConditionalGeneration.from_pretrained('./fine_tuned_t5_1000dp').to(device)\ntokenizer = T5Tokenizer.from_pretrained('./fine_tuned_t5_1000dp')\n\n# Set the model to evaluation mode\nmodel.eval()\n\n# Assume you have test_data available, which contains the 'input_text'\n# If you have already defined test_dataset, we extract test_data from it\ntest_data = test_dataset[:]  # Test data to generate predictions\n\n# Function to generate text from the input data\ndef generate_text(inputs):\n    # Tokenize and prepare input tensors\n    inputs = tokenizer.batch_encode_plus(inputs, return_tensors=\"pt\", padding=True, truncation=True, max_length=352)\n    inputs = {key: value.to(device) for key, value in inputs.items()}\n\n    # Generate text predictions without calculating gradients\n    with torch.no_grad():\n        outputs = model.generate(**inputs, max_length=128)\n\n    # Decode the generated token IDs back into text\n    generated_texts = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n    return generated_texts\n\n# Function to extract details from generated text using regular expressions\ndef extract_details(text):\n    pattern = r'details_Brand: (.*?) L0_category: (.*?) L1_category: (.*?) L2_category: (.*?) L3_category: (.*?) L4_category: (.*)'\n    match = re.match(pattern, text)\n    if match:\n        return tuple(item if item is not None else 'na' for item in match.groups())\n    return 'na', 'na', 'na', 'na', 'na', 'na'\n\n# Function to clean repeated patterns in the generated text\ndef clean_repeated_patterns(text):\n    cleaned_data = text.split(' L4_category')[0]\n    return cleaned_data","metadata":{"execution":{"iopub.status.busy":"2024-09-04T21:26:14.915281Z","iopub.execute_input":"2024-09-04T21:26:14.915686Z","iopub.status.idle":"2024-09-04T21:26:15.932916Z","shell.execute_reply.started":"2024-09-04T21:26:14.915643Z","shell.execute_reply":"2024-09-04T21:26:15.931746Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\nbatch_size = 128\ngenerated_details = []\n\n# Loop over the test data in batches\nfor i in tqdm(range(0, len(test_dataset), batch_size), desc=\"Processing test data\"):\n    # Select a batch of data\n    batch_indices = list(range(i, min(i + batch_size, len(test_dataset))))\n    batch_data = test_dataset.select(batch_indices)\n\n    # Extract input texts from the batch\n    batch_inputs = batch_data['input_text']\n\n    # Generate predictions for the current batch\n    generated_texts = generate_text(batch_inputs)\n\n    # Extract and store details from the generated texts\n    for generated_text in generated_texts:\n        generated_details.append(extract_details(generated_text))\n\nprint('Generated info extracted.............')","metadata":{"execution":{"iopub.status.busy":"2024-09-04T21:26:15.934920Z","iopub.execute_input":"2024-09-04T21:26:15.935368Z","iopub.status.idle":"2024-09-05T02:57:21.027837Z","shell.execute_reply.started":"2024-09-04T21:26:15.935322Z","shell.execute_reply":"2024-09-05T02:57:21.024290Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"Processing test data: 100%|██████████| 743/743 [5:31:05<00:00, 26.74s/it]  ","output_type":"stream"},{"name":"stdout","text":"Generated info extracted.............\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"import re\nfrom sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, classification_report\nfrom transformers import T5ForConditionalGeneration, T5Tokenizer\nimport torch\nimport numpy as np\n\n# Load the fine-tuned model and tokenizer\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = T5ForConditionalGeneration.from_pretrained('./fine_tuned_t5_1000dp').to(device)\ntokenizer = T5Tokenizer.from_pretrained('./fine_tuned_t5_1000dp')\n\n# Set the model to evaluation mode\nmodel.eval()\n\n# Define a function to generate text\ndef generate_text(inputs):\n    inputs = tokenizer.batch_encode_plus(inputs, return_tensors=\"pt\", padding=True, truncation=True, max_length=352)\n    inputs = {key: value.to(device) for key, value in inputs.items()}\n    with torch.no_grad():\n        outputs = model.generate(**inputs, max_length=128)\n    generated_texts = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n    return generated_texts\n\n# Define a function to extract details from generated text\ndef extract_details(text):\n    pattern = r'details_Brand: (.*?) L0_category: (.*?) L1_category: (.*?) L2_category: (.*?) L3_category: (.*?) L4_category: (.*)'\n    match = re.match(pattern, text)\n    if match:\n        return tuple(item if item else 'na' for item in match.groups())\n    return ('na', 'na', 'na', 'na', 'na', 'na')\n\n# Extract true categories from target texts\ndef extract_true_categories(target_text):\n    pattern = r'details_Brand: (.*?) L0_category: (.*?) L1_category: (.*?) L2_category: (.*?) L3_category: (.*?) L4_category: (.*)'\n    match = re.match(pattern, target_text)\n    if match:\n        return tuple(item if item else 'na' for item in match.groups())\n    return ('na', 'na', 'na', 'na', 'na', 'na')\n\n# Define a function to calculate metrics for each category\ndef calculate_metrics(predictions, targets):\n    metrics = {}\n    categories = ['details_Brand', 'L0_category', 'L1_category', 'L2_category', 'L3_category', 'L4_category']\n    category_indices = [0, 1, 2, 3, 4, 5]\n\n    for idx, category in zip(category_indices, categories):\n        pred_category = [pred[idx] for pred in predictions]\n        true_category = [true[idx] for true in targets]\n\n        # Print some examples for manual verification\n        print(f\"Category: {category}\")\n        print(f\"Predictions: {pred_category[:10]}\")\n        print(f\"True Labels: {true_category[:10]}\")\n\n        # Calculate metrics\n        accuracy = accuracy_score(true_category, pred_category)\n        precision = precision_score(true_category, pred_category, average='macro', zero_division=0)\n        recall = recall_score(true_category, pred_category, average='macro', zero_division=0)\n        f1 = f1_score(true_category, pred_category, average='macro', zero_division=0)\n\n        metrics[category] = {\n            'accuracy': accuracy,\n            'precision': precision,\n            'recall': recall,\n            'f1': f1\n        }\n\n    return metrics\n\n# Main evaluation function\ndef evaluate_model(val_dataset):\n    batch_size = 128\n    predictions = []\n    targets = []\n\n    for i in range(0, len(val_dataset), batch_size):\n        batch_data = val_dataset[i:i + batch_size]\n        batch_inputs = batch_data['input_text']\n        batch_targets = batch_data['target_text']\n\n        # Generate predictions\n        generated_texts = generate_text(batch_inputs)\n\n        # Extract details from generated texts and targets\n        batch_predictions = [extract_details(text) for text in generated_texts]\n        batch_targets_extracted = [extract_true_categories(text) for text in batch_targets]\n\n        predictions.extend(batch_predictions)\n        targets.extend(batch_targets_extracted)\n\n    # Calculate metrics\n    metrics = calculate_metrics(predictions, targets)\n\n    # Print metrics in the desired format\n    for category, values in metrics.items():\n        print(f\"Current Category: {category}\")\n        print(f\"  accuracy: {values['accuracy']:.4f}\")\n        print(f\"  precision: {values['precision']:.4f}\")\n        print(f\"  recall: {values['recall']:.4f}\")\n        print(f\"  f1: {values['f1']:.4f}\\n\")\n\n# Assuming val_dataset is a list of dictionaries with 'input_text' and 'target_text'\nevaluate_model(val_dataset)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-05T02:57:21.032406Z","iopub.execute_input":"2024-09-05T02:57:21.033046Z","iopub.status.idle":"2024-09-05T03:01:03.064918Z","shell.execute_reply.started":"2024-09-05T02:57:21.032983Z","shell.execute_reply":"2024-09-05T03:01:03.063230Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Category: details_Brand\nPredictions: ['Pendleton', 'JP London', 'Lawn Fawn', 'ANCHEER', 'Schecter', 'ZOTAC', 'Winning Streak', 'Coverking', 'Panther Print', 'Old World Christmas']\nTrue Labels: ['Pendleton', 'JP London', 'Lawn Fawn', 'ANCHEER', 'Schecter', 'ZOTAC', 'Winning Streak', 'Coverking', 'Panther Print', 'Old World Christmas']\nCategory: L0_category\nPredictions: ['Home & Kitchen', 'Tools & Home Improvement', 'Patio, Lawn & Garden', 'Sports & Outdoors', 'Musical Instruments', 'Electronics', 'Sports & Outdoors', 'Automotive', 'Home & Kitchen', 'Home & Kitchen']\nTrue Labels: ['Home & Kitchen', 'Tools & Home Improvement', 'Arts, Crafts & Sewing', 'Sports & Outdoors', 'Musical Instruments', 'Electronics', 'Sports & Outdoors', 'Automotive', 'Home & Kitchen', 'Home & Kitchen']\nCategory: L1_category\nPredictions: ['Bedding', 'Electrical', 'Outdoor Dcor', 'Sports', 'Guitars', 'Computers & Accessories', 'Fan Shop', 'Interior Accessories', 'Wall Art', 'Home Dcor Products']\nTrue Labels: ['Bedding', 'Paint, Wall Treatments & Supplies', 'Scrapbooking & Stamping', 'Exercise & Fitness', 'Guitars', 'Computers & Accessories', 'Fan Shop', 'Exterior Accessories', 'Wall Art', 'Home Dcor Products']\nCategory: L2_category\nPredictions: ['Blankets & Swaddling', 'Wall Plates & Accessories', 'Lawn Mower Parts & Accessories', 'Cycling', 'Electric Guitars', 'Computer Components', 'Clothing', 'Covers', 'Posters & Prints', 'Home Dcor Accents']\nTrue Labels: ['Blankets & Throws', 'Wall Stickers & Murals', 'Die-Cutting & Embossing', 'Cardio Training', 'Electric Guitars', 'Computer Components', 'Home & Kitchen', 'Covers', 'Posters & Prints', 'Home Dcor Accents']\nCategory: L3_category\nPredictions: ['Blankets', 'Wall Plates', 'Lawn Mower Parts & Accessories', 'Parts & Components', 'Electric Guitars', 'Internal Components', 'Banners', 'Full Car Covers', 'na', 'Hanging Ornaments']\nTrue Labels: ['Bed Blankets', 'na', 'Die-Cuts', 'Elliptical Trainers', 'Solid Body', 'Internal Components', 'Dcor', 'Full Car Covers', 'na', 'Hanging Ornaments']\nCategory: L4_category\nPredictions: ['na', 'na', 'Lawn Mower Replacement Parts', 'Power Components', 'na', 'Memory', 'na', 'na', 'na', 'na']\nTrue Labels: ['na', 'na', 'na', 'na', 'na', 'Graphics Cards', 'Wall Banners', 'na', 'na', 'na']\nCurrent Category: details_Brand\n  accuracy: 0.9640\n  precision: 0.9222\n  recall: 0.9244\n  f1: 0.9229\n\nCurrent Category: L0_category\n  accuracy: 0.8050\n  precision: 0.5829\n  recall: 0.5123\n  f1: 0.5335\n\nCurrent Category: L1_category\n  accuracy: 0.6720\n  precision: 0.3019\n  recall: 0.3003\n  f1: 0.2938\n\nCurrent Category: L2_category\n  accuracy: 0.5420\n  precision: 0.2456\n  recall: 0.2362\n  f1: 0.2235\n\nCurrent Category: L3_category\n  accuracy: 0.4790\n  precision: 0.2131\n  recall: 0.2095\n  f1: 0.2010\n\nCurrent Category: L4_category\n  accuracy: 0.6020\n  precision: 0.1630\n  recall: 0.1558\n  f1: 0.1525\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import json\n\n# Categories to save in the output file\ncategories = ['details_Brand', 'L0_category', 'L1_category', 'L2_category', 'L3_category', 'L4_category']\n\n# Open file for writing predictions in JSONL format\nwith open('attribute_validation_predictions.predict', 'w') as file:\n\n    # Iterate through generated details and assign unique ID (indoml_id)\n    for indoml_id, details in enumerate(generated_details):\n        result = {\"indoml_id\": indoml_id}\n\n        # Populate the result dictionary with predictions for each category\n        for category, value in zip(categories, details):\n            result[category] = value\n\n        # Write each prediction as a JSON object, one per line\n        file.write(json.dumps(result) + '\\n')\n\nprint(\"Predictions saved to 'attribute_validation_predictions.predict'\")","metadata":{"execution":{"iopub.status.busy":"2024-09-05T03:01:03.067209Z","iopub.execute_input":"2024-09-05T03:01:03.067654Z","iopub.status.idle":"2024-09-05T03:01:04.385439Z","shell.execute_reply.started":"2024-09-05T03:01:03.067607Z","shell.execute_reply":"2024-09-05T03:01:04.384122Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Predictions saved to 'attribute_validation_predictions.predict'\n","output_type":"stream"}]}]}